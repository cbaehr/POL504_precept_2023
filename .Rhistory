temp <- square(2:10)
square <- function(x) {
xsquared <- x^2
}
square(df$vec1)
square(2)
## We can create our OWN functions
square <- function(x) {
x^2
}
square(2)
square(df$vec1)
## We can create our OWN functions
square <- function(x) {x^2}
square(2)
square(df$vec1)
help(return)
cosine_similarity <- function(x, y) {
num <- x %*% y
denom <- sqrt(x^2) * sqrt(y^2)
out <- num / denom
return(out)
}
nums <- runif(50, max = 100)
nums
zscore <- function(x) {
out <- (x - mean(x)) / sd(x)
return(out)
}
zscore(nums)
hist(nums)
hist(zscore(nums))
mean(zscore(nums))
sd(zscore(nums))
rm(list = ls())
nums <- runif(50, max = 100)
(nums - mean(nums)) / sd(nums)
nums.z <- (nums - mean(nums)) / sd(nums)
nums <- runif(50, max = 100) # generate fifty random numbers
nums.z <- (nums - mean(nums)) / sd(nums) # compute z scores
## but what if we want to compute z scores for many variables?
zscore <- function(var) {
out <- (var - mean(var)) / sd(var)
return(out)
}
zscore(var = nums)
zscore(nums)
nums <- runif(50, max = 100) # generate fifty random numbers
nums.z <- (nums - mean(nums)) / sd(nums) # compute z scores
mean(nums.z) # mean (almost) zero
sd(nums.z) # standard deviation of one
## but what if we want to compute z scores for many variables?
zscore <- function(var) {
out <- (var - mean(var)) / sd(var)
return(out)
}
help(quanteda)
url_base <- "https://raw.githubusercontent.com/BobAdamsEE/SouthParkData/master/by-season"
urls <- paste0(url_base, "/Season-", 1:19, ".csv")
data <- map_df(urls, ~ read_csv(.x))
View(data)
class(data)
data <- data.frame(data)
class(data)
install.packages("text2vec")
library(text2vec)
dat=movie_review
View(dat)
write.csv(dat, "/Users/christianbaehr/Downloads/moviereviews.csv", row.names = F)
dat=movie_review[1:100,]
write.csv(dat, "/Users/christianbaehr/Downloads/moviereviews.csv", row.names = F)
## comma-separated values is one of many data types we can read into R
read.csv("Documents/GitHub/POL504_precept_2023/data/reviews.csv")
setwd()
setwd("")
getwd()
setwd()
ls()
setwd("/Users/christianbaehr/")
## comma-separated values is one of many data types we can read into R
read.csv("Documents/GitHub/POL504_precept_2023/data/reviews.csv")
View(fieldgls)
## comma-separated values is one of many data types we can read into R
read.csv("Documents/GitHub/POL504_precept_2023/data/reviews.csv")
## comma-separated values is one of many data types we can read into R
reviews <- read.csv("Documents/GitHub/POL504_precept_2023/data/reviews.csv")
class(reviews$review)
class(reviews$id)
## comma-separated values is one of many data types we can read into R
reviews <- read.csv("Documents/GitHub/POL504_precept_2023/data/reviews.csv")
library(quanteda)
rm(data)
library(quanteda)
reviews <- readtext("Documents/GitHub/POL504_precept_2023/data/reviews.csv")
## also convert to lowercase and remove redundant whitespace
process.text <- function(text) {
out <- gsub("\\.|,|'", " ", text) # sub. punctuation
out.lower <- tolower(out) # all lowercase
out.lower.singlespace <- gsub("\\s+", " ", out.lower) # remove redundant spaces
return(out.lower.singlespace)
}
## also convert to lowercase and remove redundant whitespace
process.text <- function(text) {
out <- gsub("\\.|,|'", " ", text) # sub. punctuation
out.lower <- tolower(out) # all lowercase
out.lower.singlespace <- gsub("\\s+", " ", out.lower) # remove redundant spaces
return(out.lower.singlespace)
}
mycleansentence <- process.text(mysentence) # notice no function objects are global
## We want to work with Herb Brooks pregame speech before the US-USSR Miracle on Ice game
mysentence <- "If we played 'em ten times, they might win nine. But not this game. Not...tonight."
mycleansentence <- process.text(mysentence) # notice no function objects are global
mycleanwords <- strsplit(mycleansentence, " ")
mycleanwords <- strsplit(mycleansentence, " ")[[1]]
mycleanwords <- strsplit(mycleansentence, split = " ")[[1]]
mycleanwords
grep("not", mycleanwords)
grep("play", mycleanwords) # indices that CONTAIN not
grep("play", mycleanwords, value = T) # return the word itself
grepl("play", mycleanwords)
logicals <- c(T, F, T, T, T, F)
characters <- c("please", "give", "me", "good", "course", "reviews")
vec1[10]
vec1 <- 1:20 # one dimensional
vec1[10]
characters[logicals]
sum(seq(1, 20)) # nested functions
## we can create our OWN functions
square <- function(x) {
x^2
}
square(2)
square(df$vec1)
rm(list = ls())
## 1.3) Your First Command
## print "Hello World!" in the Console
print("Hello World!")
## 1.4) R is a Calculator
1+1 # addition
5-3 # subtraction
2*3 # multiplication
12/4 # division
3^4 # exponentiation
## Note: R maintains the order of operations
3^4 == 3^2*2
3^4 == 3^(2*2)
mynum <- 1
vec1 <- 1:20 # one dimensional
vec2 <- sample(1:100, 20) # 20 random integers between 1 and 100
vec1[10] # query vectors using index
characters <- c("please", "give", "me", "good", "course", "reviews") # character
logicals <- c(TRUE, FALSE, TRUE, TRUE, TRUE, FALSE) # boolean
characters[logicals] # we can index using logic
mat <- cbind(vec1, vec2) # two dimensional object (matrix)
mat[,] # indexing a matrix
mat[1,] # row 1
mat[,1] # column 1
mat[12,2] # row 12 column 2
mat[,1] * mat[,2] # vector operations work elementwise
mat %*% t(mat) # matrix multiplication
df <- data.frame(mat) # still 2D
View(df)
names(df) # columns
df$vec1 # convenient to call variables
## to run a function you need two things: 1) the name and 2) input/s
onetotwenty <- seq(1, 20) # seq() function; one and twenty as inputs
help(seq)
onetotwenty_by2 <- seq(from = 1, to = 20, by = 2) # explicit inputs
sum(seq(1, 20)) # nested functions
## we can create our OWN functions
square <- function(x) {
x^2
}
square(2)
square(df$vec1)
nums <- runif(50, max = 100) # generate fifty random numbers
nums.z <- (nums - mean(nums)) / sd(nums) # compute z scores
hist(nums)
hist(nums)
nums.z <- (nums - mean(nums)) / sd(nums) # compute z scores
hist(nums.z)
nums.z <- (nums - mean(nums)) / sd(nums) # compute the z scores
mean(nums.z) # mean (almost) zero
sd(nums.z) # standard deviation of one
## but what if we want to compute z scores for many variables?
zscore <- function(var) {
out <- (var - mean(var)) / sd(var)
return(out)
}
zscore(nums)
apply(mat, 2, zscore)
apply(mat, 1, zscore)
## what if we want z scores for all columns?
apply(mat, 2, zscore) ##
mat
help(apply)
## what if we want z scores for all columns?
apply(X = mat, MARGIN = 2, FUN = zscore)
## We want to work with Herb Brooks pregame speech before the US-USSR Miracle on Ice game
mysentence <- "If we played 'em ten times, they might win nine. But not this game. Not...tonight."
tolower(mysentence) # lowercase
toupper(mysentence) # uppercase
gsub("not", "NOT", mysentence) # substitute "not" with "NOT"
gsub("not", "NOT", mysentence)
gsub(",", "", mysentence)
gsub(".", "", mysentence)
gsub(".", "", mysentence) # some characters are "special"
gsub("\\.", "", mysentence) # escape with double backslash
## define a function to strip periods
remove.periods <- function(text) {
out <- gsub("\\.", "", text) # note the escape character "\\" for period
return(out) # return() to retrieve output
}
remove.periods(mysentence)
## define a function to strip periods
remove.periods <- function(text) {
out <- gsub("\\.", " ", text) # note the escape character "\\" for period
return(out) # return() to retrieve output
}
remove.periods(mysentence)
## also remove commas and apostrophes
remove.punctuation <- function(text) {
out <- gsub("\\.|,|'", " ", text) # sub. punctuation (why "|"?)
return(out)
}
remove.punctuation(mysentence)
## also remove commas and apostrophes
remove.punctuation <- function(text) {
out <- gsub("\\.|,|'", " ", text) # subs. punctuation (why "|"?)
return(out)
}
## also remove commas and apostrophes
remove.punctuation <- function(text) {
out <- gsub("\\.|,|'", " ", text) # drop punctuation (why "|"?)
return(out)
}
remove.punctuation(mysentence)
## 2) also remove commas and apostrophes
remove.punctuation <- function(text) {
out <- gsub("\\.|,|'", " ", text) # drop punctuation (why "|"?)
return(out)
}
## 2) maybe we'll also remove commas and apostrophes
remove.punctuation <- function(text) {
out <- gsub("\\.|,|'", " ", text) # drop punctuation (why "|"?)
return(out)
}
remove.punctuation(mysentence)
## 3) actually lets also convert to lowercase and remove redundant whitespace
process.text <- function(text) {
out <- gsub("\\.|,|'", " ", text) # sub. punctuation
out.lower <- tolower(out) # all lowercase
out.lower.singlespace <- gsub("\\s+", " ", out.lower) # remove redundant spaces
return(out.lower.singlespace)
}
mycleansentence <- process.text(mysentence) # notice no function objects are global
mycleanwords <- strsplit(mycleansentence, split = " ")[[1]] # break into words
mycleansentence <- process.text(mysentence) # notice no function objects are global
mycleansentence
strsplit(mycleansentence, split = " ")
mycleanwords <- strsplit(mycleansentence, split = " ")[[1]]
mycleanwords <- strsplit(mycleansentence, split = " ")
class(mycleansentence)
class(mycleanwords)
strsplit(mycleansentence, split = " ")[[1]]
grep("not", mycleanwords)
grep("play", mycleanwords)
grep("play", mycleanwords, value = T)
grepl("play", mycleanwords) # boolean
## comma-separated values is one of many data types we can read into R
reviews <- read.csv("Documents/GitHub/POL504_precept_2023/data/reviews.csv")
install.packages("quanteda")
install.packages("quanteda")
library(quanteda)
library(readtext)
install.packages("readtext")
library(quanteda)
library(readtext)
reviews <- readtext("Documents/GitHub/POL504_precept_2023/data/reviews.csv")
reviews
summary(reviews)
class(reviews)
reviews <- corpus(reviews)
class(reviews)
summary(reviews)
docvars(reviews)
summary(reviews, 5)
##
reviews <- readtext("Documents/GitHub/POL504_precept_2023/data/reviews.csv") # load data
##
reviews.raw <- readtext("Documents/GitHub/POL504_precept_2023/data/reviews.csv") # load data
reviews <- corpus(reviews.raw$review) #
View(reviews.raw)
docvars(reviews, "text") <- reviews.raw$text
summary(docvars())
summary(reviews)
docvars(reviews, "sentiment") <- reviews.raw$sentiment
summary(reviews, 10)
##
reviews.raw <- readtext("Documents/GitHub/POL504_precept_2023/data/reviews.csv", text_field = "review") # load data
class(reviews.raw)
summary(reviews.raw)
help(readtext)
##
reviews.raw <- readtext("Documents/GitHub/POL504_precept_2023/data/reviews.csv", text_field = "review") # load data
reviews <- corpus(reviews.raw)
summary(reviews, 10) # info on the corpus
##
reviews.raw <- readtext("Documents/GitHub/POL504_precept_2023/data/reviews.csv", text_field = "review") # load data
reviews <- corpus(reviews.raw) # make text variable into a "corpus"
summary(reviews, 10) # info on the corpus
## loading the text data
reviews.raw <- readtext("Documents/GitHub/POL504_precept_2023/data/reviews.csv")
reviews <- corpus(reviews.raw) # make text variable into a "corpus"
## we can easily add metadata
docvars(reviews, "text") <- reviews.raw$text
docvars(reviews, "sentiment") <- reviews.raw$sentiment
summary(reviews, 10) # retrieve document level info
## shortcut
reviews.raw <- readtext("Documents/GitHub/POL504_precept_2023/data/reviews.csv", text_field = "review")
reviews <- corpus(reviews.raw)
tokens(review)
tokens(reviews)
tokens(reviews[1])
cat(tokens(reviews[1]))
## subset our data
reviews.pos <- corpus_subset(reviews, sentiment==1)
reviews.pos.dfm <- tokens(reviews.pos) |>
dfm()
reviews.pos.dfm
reviews.pos.tokens <- tokens(reviews.pos) # tokenize
reviews.pos.dfm <- dfm(reviews.pos.tokens)
dfm
reviews.pos.dfm <- dfm(reviews.pos.tokens) # construct dfm from tokens
reviews.pos.dfm
t(reviews.pos.dfm)
test=matrix(reviews.pos.dfm)
View(test)
test=as.matrix(reviews.pos.dfm)
View(test)
## can add inputs to tokens() to pre process texts
tokens(reviews.pos,
remove_punct = T,
remove_symbols = T,
remove_numbers = T,
remove_url = T,
remove_separators = T) |>
tokens_remove(stopwords("en"))
## can add inputs to tokens() to pre process texts
tokens(reviews.pos,
remove_punct = T,
remove_symbols = T,
remove_numbers = T,
remove_url = T,
remove_separators = T) |>
tokens_remove(stopwords("en"))
topfeatures(reviews.pos.tokens)
topfeatures(reviews.pos.dfm)
reviews.pos.cleantokens <- tokens(reviews.pos,
remove_punct = T,
remove_symbols = T,
remove_numbers = T,
remove_url = T,
remove_separators = T) |>
tokens_remove(stopwords("en"))
reviews.pos.cleandfm <- dfm(reviews.pos.cleantokens) # construct dfm from tokens
topfeatures(reviews.pos.cleandfm)
library(quanteda.textplots)
install.packages("quanteda.textplots")
library(quanteda.textplots)
textplot_wordcloud(reviews.pos.cleandfm, min_count = 5)
textplot_wordcloud(reviews.pos.cleandfm, min_count = 5,
color = RColorBrewer::brewer.pal(8, "Dark2"))
topfeatures(reviews.pos.cleandfm)
reviews.pos.tokens
reviews.raw[10]
reviews.raw[10,]
reviews.raw$text[10]
help(tokens_remove)
## can add inputs to tokens() to pre process texts
reviews.pos.cleantokens <- tokens(reviews.pos,
remove_punct = T,
remove_symbols = T,
remove_numbers = T,
remove_url = T,
remove_separators = T) |>
tokens_remove(stopwords("en")) |>
tokens_remove("br")
reviews.pos.cleandfm <- dfm(reviews.pos.cleantokens)
topfeatures(reviews.pos.cleandfm)
library(quanteda.textplots)
textplot_wordcloud(reviews.pos.cleandfm, min_count = 5,
color = RColorBrewer::brewer.pal(8, "Dark2"))
textplot_wordcloud(reviews.pos.cleandfm, min_count = 5, random_order = F,
color = RColorBrewer::brewer.pal(8, "Dark2"))
textplot_wordcloud(reviews.pos.cleandfm, min_count = 5, random_order = F, rotation = 0.25
color = RColorBrewer::brewer.pal(8, "Dark2"))
textplot_wordcloud(reviews.pos.cleandfm, min_count = 5, random_order = F, rotation = 0.25,
color = RColorBrewer::brewer.pal(8, "Dark2"))
textplot_wordcloud(reviews.pos.cleandfm, min_count = 1, random_order = F, rotation = 0.25,
color = RColorBrewer::brewer.pal(8, "Dark2"))
textplot_wordcloud(reviews.pos.cleandfm, min_count = 10, random_order = F, rotation = 0.25,
color = RColorBrewer::brewer.pal(8, "Dark2"))
textplot_wordcloud(reviews.pos.cleandfm, min_count = 5, random_order = F, rotation = 0.25,
color = RColorBrewer::brewer.pal(8, "Dark2"))
dim(reviews.pos.cleandfm)
dim(reviews.pos.dfm)
dim(reviews.pos.dfm)
dim(reviews.pos.cleandfm)
2840-2633
207/2840
(2840-2633) / 2840
topfeatures(reviews.pos.cleandfm)
topfeatures(reviews.pos.cleandfm, 20)
help(topfeatures)
rm(list = ls())
## 1.3) Your First Command
## print "Hello World!" in the Console
print("Hello World!")
## 1.4) R is a Calculator
1+1 # addition
5-3 # subtraction
2*3 # multiplication
12/4 # division
3^4 # exponentiation
## Note: R maintains the order of operations
3^4 == 3^2*2
3^4 == 3^(2*2)
mynum <- 1
vec1 <- 1:20 # one dimensional
vec2 <- sample(1:100, 20) # 20 random integers between 1 and 100
## 1.4) R is a Calculator
1+1 # addition
5-3 # subtraction
2*3 # multiplication
12/4 # division
3^4 # exponentiation
## Note: R maintains the order of operations
3^4 == 3^2*2
3^4 == 3^(2*2)
mynum <- 1
vec1 <- 1:20 # one dimensional
vec2 <- sample(1:100, 20) # 20 random integers between 1 and 100
vec1[10] # query vectors using index
characters <- c("please", "give", "me", "good", "course", "reviews") # character
logicals <- c(TRUE, FALSE, TRUE, TRUE, TRUE, FALSE) # boolean
characters[logicals] # we can index using logic
mat <- cbind(vec1, vec2) # two dimensional object (matrix)
mat[,] # indexing a matrix
mat[1,] # row 1
mat[,1] # column 1
mat[12,2] # row 12 column 2
mat[,1] * mat[,2] # vector operations work elementwise
mat %*% t(mat) # matrix multiplication
df <- data.frame(mat) # still 2D
View(df)
names(df) # columns
df$vec1 # convenient to call variables
## to run a function you need two things: 1) the name and 2) input/s
onetotwenty <- seq(1, 20) # seq() function; one and twenty as inputs
help(seq)
onetotwenty_by2 <- seq(from = 1, to = 20, by = 2) # explicit inputs
sum(seq(1, 20)) # nested functions
nums <- runif(50, max = 100) # 50 U(0,100) draws
hist(nums)
nums.z <- (nums - mean(nums)) / sd(nums) # compute the z scores
mean(nums.z) # mean (almost) zero
sd(nums.z) # standard deviation of one
## but what if we want to compute z scores for many variables?
zscore <- function(var) {
out <- (var - mean(var)) / sd(var)
return(out)
}
zscore(nums) # functions often run vectorwise
## what if we want z scores for all columns?
apply(X = mat, MARGIN = 2, FUN = zscore) # apply() for 2D objects
## Excerpt from Herb Brooks pregame speech before the US-USSR Miracle on Ice game
mysentence <- "If we played 'em ten times, they might win nine. But not this game. Not...tonight."
tolower(mysentence) # lowercase
toupper(mysentence) # uppercase
gsub("not", "NOT", mysentence) # substitute "not" with "NOT"
gsub(",", "", mysentence) # works for punctuation
gsub(".", "", mysentence) # some characters are "special"
gsub("\\.", "", mysentence) # escape with double backslash
## define a function to strip periods
remove.periods <- function(text) {
out <- gsub("\\.", " ", text) # note the escape character "\\" for period
return(out) # return() to retrieve output
}
help(sapply)
mean(nums)
1.5:10 # always increments by 1, and may not get to top number
## last
getwd()
setwd("Documents/Github/POL504_precept_2023/")
setwd(..)
setwd("/..")
## last
getwd()
setwd()
setwd("")
setwd("Documents/Github/POL504_precept_2023/") # change the working directory
setwd("/Users/christianbaehr/")
setwd()
setwd("../")
getwd()
setwd("/Users/christianbaehr/")
ls()
setwd("/Users/christianbaehr/Documents/GitHub/POL504_precept_2023/")
reviews.raw <- readtext("data/reviews.csv")
## SHORTCUT: add "text_field" to readtext()
reviews.raw <- readtext("data/reviews.csv", text_field = "review")
